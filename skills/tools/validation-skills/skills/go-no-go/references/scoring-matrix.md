# Weighted Scoring Matrix

Complete rubrics for each dimension of the go/no-go scoring matrix, calibration data from external tools, and threshold interpretation guidance.

---

## Scoring Rubrics by Dimension

### Dimension 1: Problem Severity (Weight: 15%)

| Score | Level | Criteria |
|-------|-------|----------|
| 5 | Hair-on-fire | People actively searching for solutions daily. Paying for inferior workarounds. Multiple early adopter criteria met (4/4). Pain costs them real money or significant time weekly. |
| 4 | Significant | Regular searching, some workarounds in use. 3/4 early adopter criteria met. Pain is real but not constant. |
| 3 | Moderate | Some people have the problem, some discuss it. 2/4 early adopter criteria. Problem exists but not urgent. |
| 2 | Mild | Problem exists but rarely discussed. People tolerate it. 1/4 early adopter criteria. Nice-to-solve but not painful. |
| 1 | Nonexistent | No evidence of others having the problem. Only the founder experiences it. 0/4 early adopter criteria. |

**Early Adopter Criteria (all 4 must be true for score 5):**
1. They HAVE the problem (actively, right now)
2. They KNOW they have the problem (can articulate it)
3. They have BUDGET/AUTHORITY to solve it
4. They have already COBBLED together a workaround

### Dimension 2: Demand Evidence (Weight: 15%)

| Score | Level | Criteria |
|-------|-------|----------|
| 5 | Overwhelming | Search volume > 1,000/mo, CPC > $2, 10+ active community threads, growing trend. Multiple independent data sources confirm demand. |
| 4 | Strong | Search volume 500-1,000/mo, CPC > $1, 5+ community threads, stable/growing trend. |
| 3 | Moderate | Search volume 100-500/mo, CPC > $0, some community discussion. Or strong community signal but low search volume. |
| 2 | Weak | Search volume < 100/mo, minimal CPC, 1-2 community mentions. Or search volume from tangential keywords only. |
| 1 | None | Zero relevant search volume, zero CPC, no community evidence. Problem may be real but people are not searching for solutions. |

### Dimension 3: Competitive Gap (Weight: 10%)

| Score | Level | Criteria |
|-------|-------|----------|
| 5 | Wide open | Competitors exist (market validated) but have clear, documented weaknesses. Strong negative reviews. Your differentiation is specific and valued. |
| 4 | Good gap | Several competitors, identifiable gaps in features/pricing/audience. Your angle fills a specific unmet need. |
| 3 | Moderate | Competitive market with some differentiation possible. Gaps exist but are not dramatic. |
| 2 | Narrow | Crowded market with strong incumbents. Differentiation is theoretical, not validated by customer feedback. |
| 1 | None | Either zero competitors (likely no market) or dominant incumbents with high switching costs and no gaps. |

### Dimension 4: Audience Clarity (Weight: 10%)

| Score | Level | Criteria |
|-------|-------|----------|
| 5 | Crystal clear | Can describe ideal customer with specificity: job title, company size, specific use case, where they spend time online, what they currently use. Have talked to 5+ members of this segment. |
| 4 | Clear | Specific audience segment defined with evidence. Know where they congregate. Have some direct interaction data. |
| 3 | Emerging | General idea of audience but not highly specific. "Small business owners" vs "independent craft shop owners with 20-100 SKUs." |
| 2 | Vague | "Anyone who has this problem" or "SMBs" without further specificity. No evidence of where to find them. |
| 1 | Unknown | Cannot describe the target customer. "Everyone" is the answer. No idea where to reach them. |

### Dimension 5: Positioning Resonance (Weight: 5%)

| Score | Level | Criteria |
|-------|-------|----------|
| 5 | Instant recognition | Target customers say "this was built for me" within seconds. Landing page headline uses their exact language. Message match is tight across all channels. |
| 4 | Clear resonance | Positioning connects with audience. VOC language used. Some evidence of message-market fit from smoke test or outreach. |
| 3 | Adequate | Positioning is logical but not tested. Uses customer language from research but no behavioral confirmation. |
| 2 | Unclear | Positioning is in builder language, not customer language. Not clearly differentiated from competitors. |
| 1 | Misaligned | Positioning does not connect with any identified audience segment. Or no positioning work done. |

### Dimension 6: Pricing Viability (Weight: 10%)

| Score | Level | Criteria |
|-------|-------|----------|
| 5 | Highly viable | Price validated by behavior (someone paid). LTV:CAC > 5:1. Breakeven at < 50 customers. Competitors priced higher for inferior product. |
| 4 | Viable | Price anchored to competitors and value-justified. LTV:CAC >= 3:1. Breakeven at reasonable customer count. Unit economics work on paper. |
| 3 | Plausible | Price set based on research but untested. LTV:CAC estimated at 2-3:1. Breakeven requires moderate customer count. |
| 2 | Questionable | Price not well-anchored. LTV:CAC < 2:1. High CAC or low margins. Breakeven requires aggressive assumptions. |
| 1 | Not viable | Unit economics do not work. Price cannot cover costs at any realistic scale. Or no pricing work done. |

### Dimension 7: Demand Validation / Smoke Test (Weight: 15%)

| Score | Level | Criteria |
|-------|-------|----------|
| 5 | Exceptional | Someone paid real money (strongest signal). Or: > 5% cold traffic conversion to trial. Pre-payments received. Multiple commitment-ladder signals. |
| 4 | Strong | 3-5% cold traffic conversion to trial/signup. Strong outreach response rates. Behavioral evidence of intent. |
| 3 | Baseline | 1-3% cold traffic conversion. Some interest but not overwhelming. Mixed signals across channels. |
| 2 | Weak | < 1% cold traffic conversion at 300+ sessions. Interest from warm traffic only. Mostly email captures, no higher-commitment actions. |
| 1 | None | No smoke test conducted, or < 0.5% conversion at 500+ sessions. Zero pre-payments or trial signups from cold traffic. |

### Dimension 8: Distribution Feasibility (Weight: 10%)

| Score | Level | Criteria |
|-------|-------|----------|
| 5 | Highly feasible | Multiple proven channels identified. Active communities where target customers discuss the problem. Outreach producing responses. Built-in viral mechanics in product. |
| 4 | Feasible | 2-3 channels identified and partially tested. Communities exist. Some outreach success. Manual distribution working. |
| 3 | Moderate | Channels identified but not tested. Communities exist but small or hard to access. Distribution requires significant ongoing effort. |
| 2 | Challenging | Few clear channels. Target audience hard to reach. No organic distribution mechanics. Paid acquisition required. |
| 1 | Infeasible | Cannot identify how to reach target customers. No communities, no search demand, no organic distribution path. |

### Dimension 9: Founder-Market Fit (Weight: 5%)

| Score | Level | Criteria |
|-------|-------|----------|
| 5 | Perfect fit | Personally experienced the problem. Domain expert. Willing and able to do distribution work for years. Passionate about the problem space, not just the solution. |
| 4 | Strong fit | Close to the problem. Strong domain understanding. Committed to the work. |
| 3 | Moderate fit | Understands the problem intellectually but has not lived it. Willing to learn the domain. |
| 2 | Weak fit | Building for a market they do not understand well. Motivated by opportunity, not experience. |
| 1 | No fit | No connection to the problem or audience. Building because it seemed like a good idea, not from experience. |

### Dimension 10: Risk Profile (Weight: 5%, INVERTED)

| Score | Level | Criteria |
|-------|-------|----------|
| 5 | Low risk | 0-1 minor risks identified. No critical dependencies. Technology is proven. Market is accessible. |
| 4 | Manageable | 1-2 moderate risks with clear mitigation strategies. No deal-breakers. |
| 3 | Moderate | 2-3 risks including one significant one. Mitigation possible but requires effort. |
| 2 | High | Multiple significant risks. 1+ critical risk that could kill the business. Platform dependency or regulatory exposure. |
| 1 | Critical | Multiple critical risks with no clear mitigation. High probability of failure from external factors. |

---

## Threshold Calibration

### External Validation Tool Benchmarks

Based on analysis of existing validation tools and their scoring approaches:

**ValidatorAI calibration data:**
- Average score across all validated ideas: 67.7/100
- Only 7.1% of validated ideas result in the founder taking meaningful action
- Most ideas score between 55-75 (Conditional Go range)
- Very few ideas score above 80 (strong GO)

**DigitalApplied 48-Hour Sprint methodology:**
- Uses 10 criteria with specific weights, each scored 1-5
- Total possible: 100 points (weighted sum)
- Thresholds: 75+ = Strong Go, 55-74 = Proceed with validation, 40-54 = Pivot, <40 = Kill

**Implications for calibration:**
- Scoring above 75 is rare and indicates genuinely strong validation
- Most viable products initially score 55-70 and improve through iteration
- A score of 40-55 does not mean the idea is bad -- it means more work is needed
- Scores below 40 should trigger serious reconsideration, not automatic killing

### Score Distribution Expectations

For a typical itch product going through all 8 phases:

| Score Range | % of Products | Typical Situation |
|------------|--------------|-------------------|
| 80-100 | ~5% | Exceptional product-market alignment. Rare. |
| 65-79 | ~25% | Strong foundation, specific gaps to address. Most successful indie products start here. |
| 50-64 | ~35% | Promising but needs significant iteration. The most common range. |
| 35-49 | ~25% | Fundamental issues. Pivot or significant change needed. |
| Below 35 | ~10% | No evidence of viability. Kill or accept as personal tool. |

---

## Meta-Scoring: Three-Axis Check

As a secondary validation, check the score across three axes:

### Axis 1: Customer Clarity
Average of: Problem Severity + Audience Clarity + Founder-Market Fit
- **Question answered:** "Do we know who we are serving and what they need?"
- Score > 3.5: Clear customer understanding
- Score < 2.5: Fundamental customer discovery needed

### Axis 2: Demand Strength
Average of: Demand Evidence + Demand Validation + Competitive Gap
- **Question answered:** "Is there proven demand for this specific solution?"
- Score > 3.5: Strong demand evidence
- Score < 2.5: Insufficient demand proof

### Axis 3: Execution Readiness
Average of: Pricing Viability + Distribution Feasibility + Risk Profile
- **Question answered:** "Can we actually reach customers and make money?"
- Score > 3.5: Ready to execute
- Score < 2.5: Execution plan needs work

**Interpretation:**
- All three axes above 3.5: GO
- One axis below 2.5: Address that axis specifically before proceeding
- Two or more axes below 2.5: PIVOT or KILL

---

## Pivot Patterns

When the score suggests PIVOT, the most common successful pivots for itch products are audience pivots, not product pivots.

### Audience Pivot
Keep the product, change who you are targeting.

**Signals:**
- "Every sale feels like pushing a boulder uphill"
- A different group of people uses it in ways you did not expect
- One segment retains dramatically better than others
- Power users share a common characteristic you had not identified

**Famous examples:**
- Slack: Built for game developers, became THE tool for all knowledge workers
- Shopify: Online snowboard store -> people asked about the platform -> e-commerce infrastructure
- Yelp: Email-based friend recommendations -> users started writing public reviews unprompted

### Positioning Pivot
Keep the product AND audience, change the message.

**Signals:**
- Users understand the product once they use it, but the landing page does not convert
- Demos go well but cold traffic does not respond
- Different positioning angles produce wildly different response rates

### Feature Pivot
Keep the audience, change the core product focus.

**Signals:**
- A side feature gets more engagement than the core product
- Users consistently request the same capability
- Usage data shows one feature used 10x more than others

### What to Keep When Pivoting
The SaaStr framework: pivot AROUND what is working.
- Keep: Core technology, domain expertise, customer relationships, market insights
- Change: Target audience, positioning, go-to-market, or product features
- A real pivot plants one foot and swings the other
- Changing everything is not a pivot -- it is starting over (which is also valid, just be honest about it)
